{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM7lQU520UJbByHgxJghSNy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktakano/takanolab/blob/master/week6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJOyLI1m_2PI"
      },
      "source": [
        "# AI演習 第6回\n",
        "### ディープラーニングによる自然言語処理 (1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FRXS85qAZmY"
      },
      "source": [
        "### 自然言語処理とは\n",
        "* 日本語、英語、タイ語など、日常の会話などで使用する言語を自然言語と言います。\n",
        "自然言語処理とは、自然言語を対象として単語や句の抽出や、係り受けの解析といった処理を経て、コンピュータが機械翻訳、自動要約、文章分類、文脈理解、会話生成などを行えるようにするための処理です。\n",
        "\n",
        "* 自然言語処理の応用例\n",
        " * 文書分類\n",
        " * 検索\n",
        " * 機械翻訳\n",
        " * 文書要約\n",
        " * 質問応答\n",
        " * 対話\n",
        " * 品詞タグ付け\n",
        " * 単語分割\n",
        " * 語義曖昧性解消\n",
        " * 固有表現抽出\n",
        " * 構文解析\n",
        " * 述語項構造認識\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aIsWInjUrU2"
      },
      "source": [
        "### 自然言語処理とディープラーニング\n",
        "* トピックモデルによる文書中の単語の出現確率の推定や隠れマルコフモデルによる品詞推定などが行われてきました。\n",
        "\n",
        "* 2013年にword2vecのような単語の分散表現をニューラルネットワークで学習する方式が考案され、さらにRNNやLSTMが自然言語処理に適用されるとともに、機械翻訳、対話文生成、自動要約、画像説明文の生成などの応用が広がっていきました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QANFdYqQW4ri"
      },
      "source": [
        "### 言語モデルと文脈\n",
        "* 単語が文書中に出現する過程を確率過程と見なし、単語がある位置に出現する確率を計算するモデルを言語モデルといいます。また言語モデルにおいて，ある単語の出現確率を計算する際に用いる周囲の単語を文脈といいます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiV4yWRxbBtk"
      },
      "source": [
        "### 自然言語処理の流れ\n",
        "\n",
        "1.   データセットの準備\n",
        "2.   前処理\n",
        "3.   単語の数値化\n",
        "4.   データセットの学習 = 応用モデルの構築\n",
        "5.   応用モデルによる分類や回帰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iib5GxyjHmAQ"
      },
      "source": [
        "### 前処理\n",
        "* 形態素解析、n-gram分割、ストップワードなどの処理をして、文章を解析プログラムが処理しやすい形式に加工することです。\n",
        "\n",
        " * 表記の統一\n",
        " * 小文字化と大文字化\n",
        " * 単語置換\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cf5GuUsQ9ey"
      },
      "source": [
        "### 形態素解析の実行例\n",
        "\n",
        "形態素解析ライブラリjanomeを利用した形態素解析の実行例です。最初にjanomeをインストールしています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3tuDZHndDQI",
        "outputId": "0a366595-1cd6-4e87-b96b-dc9756aa4087",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install janome"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 69.5MB/s \n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6bvuBeqcmY_",
        "outputId": "59a48a88-08b0-49f2-90dd-3fb3e70dd99e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "text = '私は空を見て、あなたは鏡をのぞき込む。'\n",
        "\n",
        "jt = Tokenizer()\n",
        "for token in jt.tokenize(text):\n",
        "  print(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
            "空\t名詞,一般,*,*,*,*,空,ソラ,ソラ\n",
            "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
            "見\t動詞,自立,*,*,一段,連用形,見る,ミ,ミ\n",
            "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
            "、\t記号,読点,*,*,*,*,、,、,、\n",
            "あなた\t名詞,代名詞,一般,*,*,*,あなた,アナタ,アナタ\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
            "鏡\t名詞,一般,*,*,*,*,鏡,カガミ,カガミ\n",
            "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
            "のぞき込む\t動詞,自立,*,*,五段・マ行,基本形,のぞき込む,ノゾキコム,ノゾキコム\n",
            "。\t記号,句点,*,*,*,*,。,。,。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dQrgL0PdZVH",
        "outputId": "13cfb963-dd30-4e93-e007-da55259aece4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for token in jt.tokenize(text, wakati=True):\n",
        "  print(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "私\n",
            "は\n",
            "空\n",
            "を\n",
            "見\n",
            "て\n",
            "、\n",
            "あなた\n",
            "は\n",
            "鏡\n",
            "を\n",
            "のぞき込む\n",
            "。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RovHcmNZeK6V"
      },
      "source": [
        "### 単語の数値化\n",
        "* 単語間の関連性などを定量的に計算できるように、単語を数値化します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BQqy1otqT41"
      },
      "source": [
        "text = 'I look at sky and you look in mirror.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6R6ykJgmKSj"
      },
      "source": [
        "text = text.lower()\n",
        "text = text.replace('.', ' .')\n",
        "words = text.split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwn6uLqWlsK7"
      },
      "source": [
        "def word2id(words):\n",
        "\n",
        "  word_to_id = {}\n",
        "  \n",
        "  for word in words:\n",
        "    if word not in word_to_id:\n",
        "      new_id = len(word_to_id)\n",
        "      word_to_id[word] = new_id\n",
        "  \n",
        "  return word_to_id\n",
        "  \n",
        "def id2word(word_to_id):\n",
        "  id_to_word = {}\n",
        "  for word, id in word_to_id.items():\n",
        "    id_to_word[id] = word\n",
        "\n",
        "  return id_to_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b5HAFR4nyKF",
        "outputId": "aed93e94-b04c-4627-8640-6bf2810b23d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_to_id = word2id(words)\n",
        "print(word_to_id)\n",
        "\n",
        "id_to_word = id2word(word_to_id)\n",
        "print(id_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'i': 0, 'look': 1, 'at': 2, 'sky': 3, 'and': 4, 'you': 5, 'in': 6, 'mirror': 7, '.': 8}\n",
            "{0: 'i', 1: 'look', 2: 'at', 3: 'sky', 4: 'and', 5: 'you', 6: 'in', 7: 'mirror', 8: '.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR9D50p0I1dw"
      },
      "source": [
        "### One-hotベクトル表現\n",
        "要素の値が0と1からなり、かつ1か所だけが1のベクトルです。自然言語を処理するニューラルネットワークでは、one-hotベクトルで表現されたものを入力とすることが多いです。\n",
        "\n",
        "'I look at sky and you look in mirror.'<br>\n",
        "を上の例のように分解した場合、数値を要素番号とすると各単語のone-hotベクトルを下記のように生成することができます。\n",
        "\n",
        "i: [1, 0, 0, 0, 0, 0, 0, 0, 0] <br>\n",
        "look: [0, 1, 0, 0, 0, 0, 0, 0, 0] <br>\n",
        "at: [0, 0, 1, 0, 0, 0, 0, 0, 0] <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pczPYaF5k_6m"
      },
      "source": [
        "def make_one_hot(corpus):\n",
        "    N = corpus.shape[0]\n",
        "    dim =len(word_to_id)\n",
        "\n",
        "    one_hot = np.zeros((N, dim), dtype=np.int32)\n",
        "    for idx, word_id in enumerate(corpus):\n",
        "        one_hot[idx, word_id] = 1\n",
        "\n",
        "    return one_hot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfnimEn_TfZ9",
        "outputId": "3dddfdad-14c2-4561-941d-4e8405a1c328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "corpus = [word_to_id[word] for word in words]\n",
        "corpus = np.array(corpus)\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "make_one_hot(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 1 6 7 8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WILtPxQYYPHF"
      },
      "source": [
        "### 単語の分散表現（埋め込み表現）\n",
        "* 単語をベクトルで表現したものです。\n",
        "* 単語分散表現を得るためのニューラルネットワークを用いた手法として，下記のものがあります。\n",
        "\n",
        " * Word2Vec\n",
        " * GloVe\n",
        " * fastText\n",
        "\n",
        "* 通常の深層学習を使用して学習させ、単語分散表現を得ることもできます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQniugEjdyrH"
      },
      "source": [
        "### Word2Vec\n",
        "* 単語の分散表現(埋め込み)を生成する手法\n",
        "\n",
        "* CBOWモデルとskip gramモデルを使用\n",
        "* 2013年にTomas Mikolovらが考案\n",
        "* 分布仮説（単語の意味は周囲の単語によって形成されるという仮説）に基づいて、単語の意味表現を学習する。\n",
        "* 2層のニューラルネットワークで学習する。隠れ層の重みが単語の分散表現となる。\n",
        "\n",
        "* 生成された単語の分散表現は、各単語の意味を表したベクトル行列となっており，単語間の距離を計算できる。\n",
        "\n",
        " * vector('Paris') - vector('France') + vector('Italy’) = vector(‘Rome’) <br>\n",
        " * vector('king') - vector('man') + vector('woman’) = vector('queen')\n",
        "\n",
        "<br>\n",
        "\n",
        "#### CBOWモデル\n",
        "\n",
        "* 複数の単語を文脈として、一つの単語を予測する。文脈単語の順序は問わない。\n",
        "<br>\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1zGpPVAQ7hBmkjEkeFMNa0p5vHXv192hq' width='60%'>\n",
        "\n",
        "#### Skip-gramモデル\n",
        "\n",
        "* 一つの単語を使用してして、複数の単語を文脈として予測する。文脈単語は、入力単語の近さに応じて重みを決める。\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=18ipD4BXzaNA9tnggGE8yZTGA0mD70rSB' width='60%'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwVwumo2ayxr"
      },
      "source": [
        "### 単語の分散表現行列の作成\n",
        "\n",
        "下記のサイトで提供されるコーパスを用いて、単語の分散表現行列を作成します。\n",
        "\n",
        "(英語) http://mattmahoney.net/dc/textdata.html <br>\n",
        "(日本語) https://github.com/Hironsan/ja.text8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwJauWPr6x8n",
        "outputId": "a40d680d-7e39-4fda-da17-b44755decb40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://mattmahoney.net/dc/text8.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-29 12:49:28--  http://mattmahoney.net/dc/text8.zip\n",
            "Resolving mattmahoney.net (mattmahoney.net)... 67.195.197.24\n",
            "Connecting to mattmahoney.net (mattmahoney.net)|67.195.197.24|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31344016 (30M) [application/zip]\n",
            "Saving to: ‘text8.zip’\n",
            "\n",
            "text8.zip           100%[===================>]  29.89M   337KB/s    in 94s     \n",
            "\n",
            "2020-10-29 12:51:02 (327 KB/s) - ‘text8.zip’ saved [31344016/31344016]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM2rcdUSaHG4",
        "outputId": "c3b7252f-1598-4b9f-d94f-f48114c6499e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip text8.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  text8.zip\n",
            "  inflating: text8                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKVoWs-bbant",
        "outputId": "06be2afb-b21b-4ed5-d770-ab814bb6608d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import logging\n",
        "from gensim.models.word2vec import Word2Vec, Text8Corpus\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        " \n",
        "sentences = Text8Corpus('text8')\n",
        "model = Word2Vec(sentences, size=100)\n",
        "\n",
        "model.save('model.bin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-29 12:56:32,385 : INFO : collecting all words and their counts\n",
            "2020-10-29 12:56:32,402 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2020-10-29 12:56:37,377 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
            "2020-10-29 12:56:37,381 : INFO : Loading a fresh vocabulary\n",
            "2020-10-29 12:56:37,604 : INFO : effective_min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
            "2020-10-29 12:56:37,605 : INFO : effective_min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
            "2020-10-29 12:56:37,849 : INFO : deleting the raw counts dictionary of 253854 items\n",
            "2020-10-29 12:56:37,860 : INFO : sample=0.001 downsamples 38 most-common words\n",
            "2020-10-29 12:56:37,861 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
            "2020-10-29 12:56:38,169 : INFO : estimated required memory for 71290 words and 100 dimensions: 92677000 bytes\n",
            "2020-10-29 12:56:38,170 : INFO : resetting layer weights\n",
            "2020-10-29 12:56:52,322 : INFO : training model with 3 workers on 71290 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2020-10-29 12:56:53,338 : INFO : EPOCH 1 - PROGRESS: at 3.41% examples, 422753 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 12:56:54,358 : INFO : EPOCH 1 - PROGRESS: at 7.11% examples, 434122 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:56:55,358 : INFO : EPOCH 1 - PROGRESS: at 10.64% examples, 435315 words/s, in_qsize 3, out_qsize 2\n",
            "2020-10-29 12:56:56,360 : INFO : EPOCH 1 - PROGRESS: at 14.29% examples, 440085 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:56:57,367 : INFO : EPOCH 1 - PROGRESS: at 18.05% examples, 445545 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 12:56:58,386 : INFO : EPOCH 1 - PROGRESS: at 21.75% examples, 446972 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:56:59,413 : INFO : EPOCH 1 - PROGRESS: at 25.46% examples, 448108 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:00,420 : INFO : EPOCH 1 - PROGRESS: at 29.04% examples, 448447 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:01,455 : INFO : EPOCH 1 - PROGRESS: at 32.75% examples, 449085 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:02,457 : INFO : EPOCH 1 - PROGRESS: at 36.39% examples, 450266 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:03,476 : INFO : EPOCH 1 - PROGRESS: at 39.92% examples, 448650 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 12:57:04,488 : INFO : EPOCH 1 - PROGRESS: at 43.56% examples, 448830 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:05,514 : INFO : EPOCH 1 - PROGRESS: at 47.27% examples, 449316 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:06,516 : INFO : EPOCH 1 - PROGRESS: at 50.91% examples, 449893 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 12:57:07,543 : INFO : EPOCH 1 - PROGRESS: at 54.67% examples, 450593 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:08,574 : INFO : EPOCH 1 - PROGRESS: at 58.32% examples, 450106 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 12:57:09,579 : INFO : EPOCH 1 - PROGRESS: at 62.02% examples, 450844 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:10,605 : INFO : EPOCH 1 - PROGRESS: at 65.67% examples, 450549 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 12:57:11,626 : INFO : EPOCH 1 - PROGRESS: at 69.37% examples, 450752 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:57:12,636 : INFO : EPOCH 1 - PROGRESS: at 73.07% examples, 451311 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:57:13,649 : INFO : EPOCH 1 - PROGRESS: at 76.90% examples, 451597 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:57:14,670 : INFO : EPOCH 1 - PROGRESS: at 80.54% examples, 451197 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:15,689 : INFO : EPOCH 1 - PROGRESS: at 84.30% examples, 451619 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:16,719 : INFO : EPOCH 1 - PROGRESS: at 88.01% examples, 451468 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 12:57:17,740 : INFO : EPOCH 1 - PROGRESS: at 91.83% examples, 452076 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:18,777 : INFO : EPOCH 1 - PROGRESS: at 95.53% examples, 451836 words/s, in_qsize 5, out_qsize 2\n",
            "2020-10-29 12:57:19,780 : INFO : EPOCH 1 - PROGRESS: at 99.18% examples, 451789 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:19,944 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-29 12:57:19,959 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-29 12:57:19,968 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-29 12:57:19,969 : INFO : EPOCH - 1 : training on 17005207 raw words (12504681 effective words) took 27.6s, 452359 effective words/s\n",
            "2020-10-29 12:57:20,976 : INFO : EPOCH 2 - PROGRESS: at 3.53% examples, 441004 words/s, in_qsize 3, out_qsize 2\n",
            "2020-10-29 12:57:21,982 : INFO : EPOCH 2 - PROGRESS: at 7.29% examples, 450177 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 12:57:22,992 : INFO : EPOCH 2 - PROGRESS: at 11.11% examples, 456528 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:24,003 : INFO : EPOCH 2 - PROGRESS: at 14.81% examples, 456994 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:25,013 : INFO : EPOCH 2 - PROGRESS: at 18.34% examples, 453208 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:26,029 : INFO : EPOCH 2 - PROGRESS: at 22.10% examples, 454827 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:27,063 : INFO : EPOCH 2 - PROGRESS: at 25.75% examples, 453607 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:28,065 : INFO : EPOCH 2 - PROGRESS: at 29.34% examples, 453462 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:29,070 : INFO : EPOCH 2 - PROGRESS: at 32.98% examples, 454164 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 12:57:30,099 : INFO : EPOCH 2 - PROGRESS: at 36.68% examples, 454216 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 12:57:31,109 : INFO : EPOCH 2 - PROGRESS: at 40.45% examples, 455284 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:32,127 : INFO : EPOCH 2 - PROGRESS: at 44.09% examples, 454808 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:33,151 : INFO : EPOCH 2 - PROGRESS: at 47.80% examples, 454827 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:57:34,164 : INFO : EPOCH 2 - PROGRESS: at 51.56% examples, 455609 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:35,175 : INFO : EPOCH 2 - PROGRESS: at 55.14% examples, 455027 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:57:36,179 : INFO : EPOCH 2 - PROGRESS: at 58.79% examples, 455014 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:37,222 : INFO : EPOCH 2 - PROGRESS: at 62.55% examples, 454846 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:57:38,251 : INFO : EPOCH 2 - PROGRESS: at 66.31% examples, 455214 words/s, in_qsize 5, out_qsize 2\n",
            "2020-10-29 12:57:39,249 : INFO : EPOCH 2 - PROGRESS: at 69.96% examples, 455227 words/s, in_qsize 3, out_qsize 2\n",
            "2020-10-29 12:57:40,257 : INFO : EPOCH 2 - PROGRESS: at 73.66% examples, 455598 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:41,282 : INFO : EPOCH 2 - PROGRESS: at 77.54% examples, 455683 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:42,307 : INFO : EPOCH 2 - PROGRESS: at 81.31% examples, 455719 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:43,325 : INFO : EPOCH 2 - PROGRESS: at 85.07% examples, 455950 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:44,337 : INFO : EPOCH 2 - PROGRESS: at 88.83% examples, 456374 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:45,343 : INFO : EPOCH 2 - PROGRESS: at 92.42% examples, 455843 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:46,348 : INFO : EPOCH 2 - PROGRESS: at 96.06% examples, 455755 words/s, in_qsize 4, out_qsize 0\n",
            "2020-10-29 12:57:47,348 : INFO : EPOCH 2 - PROGRESS: at 99.65% examples, 455387 words/s, in_qsize 4, out_qsize 2\n",
            "2020-10-29 12:57:47,396 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-29 12:57:47,398 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-29 12:57:47,403 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-29 12:57:47,405 : INFO : EPOCH - 2 : training on 17005207 raw words (12507319 effective words) took 27.4s, 455932 effective words/s\n",
            "2020-10-29 12:57:48,419 : INFO : EPOCH 3 - PROGRESS: at 3.59% examples, 447669 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:49,454 : INFO : EPOCH 3 - PROGRESS: at 7.41% examples, 450707 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:57:50,454 : INFO : EPOCH 3 - PROGRESS: at 11.17% examples, 455589 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 12:57:51,480 : INFO : EPOCH 3 - PROGRESS: at 14.87% examples, 454652 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:52,508 : INFO : EPOCH 3 - PROGRESS: at 18.52% examples, 452599 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:53,512 : INFO : EPOCH 3 - PROGRESS: at 22.16% examples, 452728 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:54,518 : INFO : EPOCH 3 - PROGRESS: at 25.63% examples, 450419 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 12:57:55,537 : INFO : EPOCH 3 - PROGRESS: at 29.28% examples, 450687 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:56,544 : INFO : EPOCH 3 - PROGRESS: at 32.80% examples, 449955 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:57,571 : INFO : EPOCH 3 - PROGRESS: at 36.45% examples, 449897 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:57:58,572 : INFO : EPOCH 3 - PROGRESS: at 40.09% examples, 450342 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:57:59,577 : INFO : EPOCH 3 - PROGRESS: at 43.80% examples, 451324 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:00,596 : INFO : EPOCH 3 - PROGRESS: at 47.50% examples, 451803 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:01,634 : INFO : EPOCH 3 - PROGRESS: at 51.21% examples, 451522 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 12:58:02,635 : INFO : EPOCH 3 - PROGRESS: at 54.85% examples, 451963 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:03,652 : INFO : EPOCH 3 - PROGRESS: at 58.50% examples, 451784 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:04,667 : INFO : EPOCH 3 - PROGRESS: at 62.20% examples, 452151 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:05,670 : INFO : EPOCH 3 - PROGRESS: at 65.84% examples, 452276 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 12:58:06,672 : INFO : EPOCH 3 - PROGRESS: at 69.43% examples, 452127 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:07,681 : INFO : EPOCH 3 - PROGRESS: at 72.96% examples, 451495 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 12:58:08,691 : INFO : EPOCH 3 - PROGRESS: at 76.66% examples, 451276 words/s, in_qsize 3, out_qsize 2\n",
            "2020-10-29 12:58:09,711 : INFO : EPOCH 3 - PROGRESS: at 80.42% examples, 451481 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:10,726 : INFO : EPOCH 3 - PROGRESS: at 84.01% examples, 451081 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:11,732 : INFO : EPOCH 3 - PROGRESS: at 87.60% examples, 450782 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:58:12,747 : INFO : EPOCH 3 - PROGRESS: at 91.36% examples, 451310 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:13,760 : INFO : EPOCH 3 - PROGRESS: at 95.06% examples, 451431 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:14,762 : INFO : EPOCH 3 - PROGRESS: at 98.65% examples, 451163 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:58:15,069 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-29 12:58:15,082 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-29 12:58:15,088 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-29 12:58:15,088 : INFO : EPOCH - 3 : training on 17005207 raw words (12506452 effective words) took 27.7s, 451914 effective words/s\n",
            "2020-10-29 12:58:16,095 : INFO : EPOCH 4 - PROGRESS: at 3.59% examples, 449374 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:17,100 : INFO : EPOCH 4 - PROGRESS: at 7.29% examples, 450832 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:18,101 : INFO : EPOCH 4 - PROGRESS: at 10.99% examples, 453446 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:19,139 : INFO : EPOCH 4 - PROGRESS: at 14.64% examples, 449538 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 12:58:20,171 : INFO : EPOCH 4 - PROGRESS: at 18.46% examples, 452543 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:21,187 : INFO : EPOCH 4 - PROGRESS: at 22.16% examples, 453004 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:58:22,190 : INFO : EPOCH 4 - PROGRESS: at 25.93% examples, 456146 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:23,200 : INFO : EPOCH 4 - PROGRESS: at 29.57% examples, 456333 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:24,205 : INFO : EPOCH 4 - PROGRESS: at 33.27% examples, 457394 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:25,234 : INFO : EPOCH 4 - PROGRESS: at 36.98% examples, 457094 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:26,247 : INFO : EPOCH 4 - PROGRESS: at 40.68% examples, 457059 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:27,266 : INFO : EPOCH 4 - PROGRESS: at 44.27% examples, 455776 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:28,286 : INFO : EPOCH 4 - PROGRESS: at 47.91% examples, 455345 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:29,306 : INFO : EPOCH 4 - PROGRESS: at 51.68% examples, 455860 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:30,306 : INFO : EPOCH 4 - PROGRESS: at 55.26% examples, 455594 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 12:58:31,331 : INFO : EPOCH 4 - PROGRESS: at 58.91% examples, 454968 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:58:32,341 : INFO : EPOCH 4 - PROGRESS: at 62.55% examples, 454806 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 12:58:33,374 : INFO : EPOCH 4 - PROGRESS: at 66.31% examples, 454915 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:34,375 : INFO : EPOCH 4 - PROGRESS: at 69.96% examples, 455003 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:35,390 : INFO : EPOCH 4 - PROGRESS: at 73.60% examples, 454911 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:58:36,392 : INFO : EPOCH 4 - PROGRESS: at 77.37% examples, 454837 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:37,407 : INFO : EPOCH 4 - PROGRESS: at 81.07% examples, 454753 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:38,433 : INFO : EPOCH 4 - PROGRESS: at 84.71% examples, 454281 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:39,451 : INFO : EPOCH 4 - PROGRESS: at 88.48% examples, 454613 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:40,467 : INFO : EPOCH 4 - PROGRESS: at 92.18% examples, 454596 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:41,483 : INFO : EPOCH 4 - PROGRESS: at 95.88% examples, 454634 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:58:42,497 : INFO : EPOCH 4 - PROGRESS: at 99.65% examples, 454877 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:42,549 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-29 12:58:42,559 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-29 12:58:42,567 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-29 12:58:42,568 : INFO : EPOCH - 4 : training on 17005207 raw words (12506236 effective words) took 27.5s, 455201 effective words/s\n",
            "2020-10-29 12:58:43,579 : INFO : EPOCH 5 - PROGRESS: at 3.64% examples, 453649 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:44,593 : INFO : EPOCH 5 - PROGRESS: at 7.35% examples, 451117 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 12:58:45,620 : INFO : EPOCH 5 - PROGRESS: at 11.11% examples, 451893 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 12:58:46,628 : INFO : EPOCH 5 - PROGRESS: at 14.87% examples, 455644 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:47,638 : INFO : EPOCH 5 - PROGRESS: at 18.58% examples, 456314 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:58:48,651 : INFO : EPOCH 5 - PROGRESS: at 22.22% examples, 455191 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:49,675 : INFO : EPOCH 5 - PROGRESS: at 25.93% examples, 455618 words/s, in_qsize 3, out_qsize 2\n",
            "2020-10-29 12:58:50,683 : INFO : EPOCH 5 - PROGRESS: at 29.57% examples, 455957 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:51,688 : INFO : EPOCH 5 - PROGRESS: at 33.27% examples, 457091 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 12:58:52,714 : INFO : EPOCH 5 - PROGRESS: at 36.98% examples, 457051 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:53,723 : INFO : EPOCH 5 - PROGRESS: at 40.68% examples, 457193 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:54,746 : INFO : EPOCH 5 - PROGRESS: at 44.33% examples, 456364 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:55,755 : INFO : EPOCH 5 - PROGRESS: at 48.03% examples, 456808 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:56,774 : INFO : EPOCH 5 - PROGRESS: at 51.73% examples, 456722 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:57,813 : INFO : EPOCH 5 - PROGRESS: at 55.44% examples, 456255 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 12:58:58,839 : INFO : EPOCH 5 - PROGRESS: at 59.14% examples, 455980 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:58:59,843 : INFO : EPOCH 5 - PROGRESS: at 62.73% examples, 455513 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:59:00,881 : INFO : EPOCH 5 - PROGRESS: at 66.55% examples, 455840 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:59:01,887 : INFO : EPOCH 5 - PROGRESS: at 70.25% examples, 456163 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:59:02,918 : INFO : EPOCH 5 - PROGRESS: at 73.90% examples, 455611 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:59:03,921 : INFO : EPOCH 5 - PROGRESS: at 77.60% examples, 455145 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:59:04,929 : INFO : EPOCH 5 - PROGRESS: at 81.25% examples, 454867 words/s, in_qsize 4, out_qsize 2\n",
            "2020-10-29 12:59:05,943 : INFO : EPOCH 5 - PROGRESS: at 85.01% examples, 455230 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:59:06,948 : INFO : EPOCH 5 - PROGRESS: at 88.65% examples, 455179 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:59:07,971 : INFO : EPOCH 5 - PROGRESS: at 92.42% examples, 455268 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 12:59:08,981 : INFO : EPOCH 5 - PROGRESS: at 96.00% examples, 454841 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:59:09,994 : INFO : EPOCH 5 - PROGRESS: at 99.65% examples, 454556 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 12:59:10,044 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-29 12:59:10,048 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-29 12:59:10,053 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-29 12:59:10,054 : INFO : EPOCH - 5 : training on 17005207 raw words (12506144 effective words) took 27.5s, 455065 effective words/s\n",
            "2020-10-29 12:59:10,055 : INFO : training on a 85026035 raw words (62530832 effective words) took 137.7s, 454004 effective words/s\n",
            "2020-10-29 12:59:10,106 : INFO : saving Word2Vec object under model.bin, separately None\n",
            "2020-10-29 12:59:10,108 : INFO : not storing attribute vectors_norm\n",
            "2020-10-29 12:59:10,109 : INFO : not storing attribute cum_table\n",
            "2020-10-29 12:59:10,935 : INFO : saved model.bin\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT5c1-GibtnA",
        "outputId": "31afc550-104a-4be8-a563-a6f91f0c4f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Word2Vec.load('model.bin')\n",
        "\n",
        "print(model.wv['dog'])\n",
        "print(model.wv['dog'].shape)\n",
        "model.wv.most_similar(['car'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-29 13:44:44,240 : INFO : loading Word2Vec object from model.bin\n",
            "2020-10-29 13:44:44,837 : INFO : loading wv recursively from model.bin.wv.* with mmap=None\n",
            "2020-10-29 13:44:44,838 : INFO : setting ignored attribute vectors_norm to None\n",
            "2020-10-29 13:44:44,838 : INFO : loading vocabulary recursively from model.bin.vocabulary.* with mmap=None\n",
            "2020-10-29 13:44:44,839 : INFO : loading trainables recursively from model.bin.trainables.* with mmap=None\n",
            "2020-10-29 13:44:44,840 : INFO : setting ignored attribute cum_table to None\n",
            "2020-10-29 13:44:44,841 : INFO : loaded model.bin\n",
            "2020-10-29 13:44:45,040 : INFO : precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-3.29781681e-01 -2.19763255e+00  7.30305552e-01  5.65891601e-02\n",
            " -8.17861676e-01 -1.90371943e+00  1.26455522e+00 -2.37285331e-01\n",
            " -1.24525465e-01  1.10376644e+00 -1.44059277e+00 -1.75673175e+00\n",
            " -1.22593246e-01  3.43172818e-01 -1.50801754e+00  9.88996148e-01\n",
            "  1.49990714e+00  1.00307012e+00  1.17061615e+00  5.34562349e-01\n",
            " -1.12042117e+00 -1.35945046e+00 -1.00587153e+00 -4.48431671e-01\n",
            " -6.88128352e-01  7.67244220e-01 -1.10500062e+00 -3.77828240e-01\n",
            "  9.81238961e-01  1.10676743e-01  1.66719943e-01  5.59021682e-02\n",
            " -1.36575317e+00  8.31565201e-01  7.43897408e-02 -2.23381925e+00\n",
            " -6.58857524e-02  1.53459504e-01  1.00218856e+00  7.57093072e-01\n",
            "  4.14303355e-02  1.65139842e+00  1.51228309e+00  1.84139416e-01\n",
            "  1.39303148e+00  6.84117138e-01 -3.13499302e-01  1.05936170e+00\n",
            " -1.56172132e+00  3.43215376e-01 -2.32463169e+00  2.44814372e+00\n",
            "  6.07408822e-01 -1.92601180e+00 -7.36339390e-01 -1.68348920e+00\n",
            "  2.99419574e-02  4.79800105e-01  1.56553817e+00 -7.70754576e-01\n",
            " -1.28482687e+00  2.15709662e+00 -6.66663110e-01 -1.21253669e+00\n",
            "  2.33023739e+00 -6.97578430e-01  5.09522915e-01  1.65036750e+00\n",
            "  1.42672980e+00 -7.13133752e-01  3.26558471e+00  1.51152790e-01\n",
            " -3.93039584e-02  6.12429202e-01 -2.08143282e+00  5.29736757e-01\n",
            " -8.44843984e-01  8.85912061e-01  4.39409167e-01  1.31143425e-02\n",
            " -6.73251629e-01  3.98351759e-01 -2.28704143e+00 -9.55274642e-01\n",
            "  1.10878456e+00 -8.10734272e-01  3.55830073e-01 -4.46313053e-01\n",
            " -5.58089852e-01  2.62955523e+00  2.43394446e+00 -1.49395418e+00\n",
            "  2.05408859e+00  1.10477128e-03 -1.39517426e+00  1.96533620e+00\n",
            "  2.02076122e-01  2.56147325e-01  1.75893772e+00  3.47223461e-01]\n",
            "(100,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('driver', 0.7645907402038574),\n",
              " ('cars', 0.7256535291671753),\n",
              " ('motorcycle', 0.7231885194778442),\n",
              " ('taxi', 0.7163602113723755),\n",
              " ('truck', 0.7151368856430054),\n",
              " ('vehicle', 0.6943105459213257),\n",
              " ('glider', 0.676424503326416),\n",
              " ('racing', 0.6492857933044434),\n",
              " ('passenger', 0.6429322957992554),\n",
              " ('automobile', 0.6412168741226196)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3XGfFKib7_P"
      },
      "source": [
        "#### 確認例題\n",
        "日本語コーパス(ja.text8.zip)をダウンロードし、同様の処理をしてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIZJt8tGEafr",
        "outputId": "ac85fc41-f035-4853-d9c1-c61a0c5b3845",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://s3-ap-northeast-1.amazonaws.com/dev.tech-sketch.jp/chakki/public/ja.text8.zip\n",
        "!unzip ja.text8.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-29 13:06:18--  https://s3-ap-northeast-1.amazonaws.com/dev.tech-sketch.jp/chakki/public/ja.text8.zip\n",
            "Resolving s3-ap-northeast-1.amazonaws.com (s3-ap-northeast-1.amazonaws.com)... 52.219.4.150\n",
            "Connecting to s3-ap-northeast-1.amazonaws.com (s3-ap-northeast-1.amazonaws.com)|52.219.4.150|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33905114 (32M) [application/zip]\n",
            "Saving to: ‘ja.text8.zip.1’\n",
            "\n",
            "ja.text8.zip.1      100%[===================>]  32.33M  41.3MB/s    in 0.8s    \n",
            "\n",
            "2020-10-29 13:06:19 (41.3 MB/s) - ‘ja.text8.zip.1’ saved [33905114/33905114]\n",
            "\n",
            "Archive:  ja.text8.zip\n",
            "replace ja.text8? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: ja.text8                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P14GRXFUTAqK",
        "outputId": "ccd0ab4a-c309-4b93-c1f7-c69950b7dcbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import logging\n",
        "from gensim.models.word2vec import Word2Vec, Text8Corpus\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        " \n",
        "sentences = Text8Corpus('ja.text8')\n",
        "model = Word2Vec(sentences, size=100)\n",
        "\n",
        "model.save('model.ja.bin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-29 13:06:37,472 : INFO : collecting all words and their counts\n",
            "2020-10-29 13:06:37,478 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2020-10-29 13:06:43,369 : INFO : collected 290811 word types from a corpus of 16900026 raw words and 1691 sentences\n",
            "2020-10-29 13:06:43,370 : INFO : Loading a fresh vocabulary\n",
            "2020-10-29 13:06:43,609 : INFO : effective_min_count=5 retains 75187 unique words (25% of original 290811, drops 215624)\n",
            "2020-10-29 13:06:43,610 : INFO : effective_min_count=5 leaves 16577418 word corpus (98% of original 16900026, drops 322608)\n",
            "2020-10-29 13:06:43,852 : INFO : deleting the raw counts dictionary of 290811 items\n",
            "2020-10-29 13:06:43,866 : INFO : sample=0.001 downsamples 34 most-common words\n",
            "2020-10-29 13:06:43,868 : INFO : downsampling leaves estimated 11431523 word corpus (69.0% of prior 16577418)\n",
            "2020-10-29 13:06:44,169 : INFO : estimated required memory for 75187 words and 100 dimensions: 97743100 bytes\n",
            "2020-10-29 13:06:44,170 : INFO : resetting layer weights\n",
            "2020-10-29 13:06:59,045 : INFO : training model with 3 workers on 75187 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2020-10-29 13:07:00,054 : INFO : EPOCH 1 - PROGRESS: at 3.55% examples, 403827 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:01,066 : INFO : EPOCH 1 - PROGRESS: at 7.16% examples, 406395 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:02,081 : INFO : EPOCH 1 - PROGRESS: at 10.70% examples, 403876 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:03,087 : INFO : EPOCH 1 - PROGRESS: at 14.25% examples, 403763 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:04,099 : INFO : EPOCH 1 - PROGRESS: at 17.68% examples, 400654 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:05,107 : INFO : EPOCH 1 - PROGRESS: at 21.23% examples, 401122 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:06,116 : INFO : EPOCH 1 - PROGRESS: at 24.66% examples, 399295 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 13:07:07,131 : INFO : EPOCH 1 - PROGRESS: at 28.27% examples, 400027 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:07:08,138 : INFO : EPOCH 1 - PROGRESS: at 31.70% examples, 398766 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:07:09,145 : INFO : EPOCH 1 - PROGRESS: at 35.30% examples, 399833 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:07:10,146 : INFO : EPOCH 1 - PROGRESS: at 38.85% examples, 400374 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:07:11,150 : INFO : EPOCH 1 - PROGRESS: at 42.34% examples, 400178 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:12,160 : INFO : EPOCH 1 - PROGRESS: at 45.95% examples, 400719 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:13,166 : INFO : EPOCH 1 - PROGRESS: at 49.62% examples, 401878 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:14,180 : INFO : EPOCH 1 - PROGRESS: at 53.22% examples, 402287 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:15,193 : INFO : EPOCH 1 - PROGRESS: at 56.95% examples, 403405 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:16,229 : INFO : EPOCH 1 - PROGRESS: at 60.67% examples, 403961 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:17,246 : INFO : EPOCH 1 - PROGRESS: at 64.34% examples, 404392 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:18,253 : INFO : EPOCH 1 - PROGRESS: at 67.83% examples, 403955 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:07:19,263 : INFO : EPOCH 1 - PROGRESS: at 71.56% examples, 405019 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:20,265 : INFO : EPOCH 1 - PROGRESS: at 75.16% examples, 405227 words/s, in_qsize 5, out_qsize 1\n",
            "2020-10-29 13:07:21,273 : INFO : EPOCH 1 - PROGRESS: at 78.77% examples, 405392 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:07:22,277 : INFO : EPOCH 1 - PROGRESS: at 82.44% examples, 405931 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:23,303 : INFO : EPOCH 1 - PROGRESS: at 86.10% examples, 405999 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:24,330 : INFO : EPOCH 1 - PROGRESS: at 89.83% examples, 406352 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:07:25,335 : INFO : EPOCH 1 - PROGRESS: at 93.44% examples, 406547 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:26,359 : INFO : EPOCH 1 - PROGRESS: at 97.16% examples, 406876 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:27,084 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-29 13:07:27,088 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-29 13:07:27,094 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-29 13:07:27,095 : INFO : EPOCH - 1 : training on 16900026 raw words (11431510 effective words) took 28.0s, 407624 effective words/s\n",
            "2020-10-29 13:07:28,109 : INFO : EPOCH 2 - PROGRESS: at 3.55% examples, 402950 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:29,118 : INFO : EPOCH 2 - PROGRESS: at 7.16% examples, 406782 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:30,128 : INFO : EPOCH 2 - PROGRESS: at 10.76% examples, 406983 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 13:07:31,152 : INFO : EPOCH 2 - PROGRESS: at 14.55% examples, 410946 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:32,182 : INFO : EPOCH 2 - PROGRESS: at 18.27% examples, 411579 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:07:33,188 : INFO : EPOCH 2 - PROGRESS: at 22.00% examples, 413595 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:34,199 : INFO : EPOCH 2 - PROGRESS: at 25.61% examples, 412651 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:07:35,203 : INFO : EPOCH 2 - PROGRESS: at 29.21% examples, 412364 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:07:36,203 : INFO : EPOCH 2 - PROGRESS: at 32.88% examples, 413138 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:37,209 : INFO : EPOCH 2 - PROGRESS: at 36.55% examples, 413511 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:07:38,231 : INFO : EPOCH 2 - PROGRESS: at 40.27% examples, 413787 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:07:39,258 : INFO : EPOCH 2 - PROGRESS: at 43.94% examples, 413389 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:40,259 : INFO : EPOCH 2 - PROGRESS: at 47.60% examples, 413734 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:41,266 : INFO : EPOCH 2 - PROGRESS: at 51.27% examples, 413980 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:42,292 : INFO : EPOCH 2 - PROGRESS: at 55.12% examples, 415005 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:43,297 : INFO : EPOCH 2 - PROGRESS: at 58.78% examples, 415152 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:07:44,336 : INFO : EPOCH 2 - PROGRESS: at 62.45% examples, 414464 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 13:07:45,357 : INFO : EPOCH 2 - PROGRESS: at 66.23% examples, 415001 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:46,362 : INFO : EPOCH 2 - PROGRESS: at 69.96% examples, 415569 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 13:07:47,370 : INFO : EPOCH 2 - PROGRESS: at 73.63% examples, 415635 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:48,389 : INFO : EPOCH 2 - PROGRESS: at 77.35% examples, 415740 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:49,398 : INFO : EPOCH 2 - PROGRESS: at 81.02% examples, 415676 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:50,417 : INFO : EPOCH 2 - PROGRESS: at 84.74% examples, 415786 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:51,423 : INFO : EPOCH 2 - PROGRESS: at 88.53% examples, 416346 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:52,444 : INFO : EPOCH 2 - PROGRESS: at 92.25% examples, 416381 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:07:53,447 : INFO : EPOCH 2 - PROGRESS: at 95.98% examples, 416724 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:07:54,463 : INFO : EPOCH 2 - PROGRESS: at 99.76% examples, 417118 words/s, in_qsize 4, out_qsize 0\n",
            "2020-10-29 13:07:54,467 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-29 13:07:54,477 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-29 13:07:54,494 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-29 13:07:54,495 : INFO : EPOCH - 2 : training on 16900026 raw words (11433077 effective words) took 27.4s, 417372 effective words/s\n",
            "2020-10-29 13:07:55,516 : INFO : EPOCH 3 - PROGRESS: at 3.67% examples, 413302 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:56,528 : INFO : EPOCH 3 - PROGRESS: at 7.45% examples, 421341 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 13:07:57,561 : INFO : EPOCH 3 - PROGRESS: at 11.35% examples, 424409 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:07:58,595 : INFO : EPOCH 3 - PROGRESS: at 15.20% examples, 424540 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:07:59,599 : INFO : EPOCH 3 - PROGRESS: at 18.92% examples, 424810 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:00,617 : INFO : EPOCH 3 - PROGRESS: at 22.71% examples, 424829 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:01,654 : INFO : EPOCH 3 - PROGRESS: at 26.55% examples, 424666 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:02,662 : INFO : EPOCH 3 - PROGRESS: at 30.16% examples, 422547 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:03,665 : INFO : EPOCH 3 - PROGRESS: at 33.94% examples, 423538 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:04,668 : INFO : EPOCH 3 - PROGRESS: at 37.61% examples, 422925 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:08:05,679 : INFO : EPOCH 3 - PROGRESS: at 41.45% examples, 424037 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:06,687 : INFO : EPOCH 3 - PROGRESS: at 45.06% examples, 422732 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:07,705 : INFO : EPOCH 3 - PROGRESS: at 48.73% examples, 421830 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:08:08,726 : INFO : EPOCH 3 - PROGRESS: at 52.45% examples, 421555 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:09,747 : INFO : EPOCH 3 - PROGRESS: at 56.12% examples, 420838 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:10,778 : INFO : EPOCH 3 - PROGRESS: at 59.85% examples, 420351 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 13:08:11,810 : INFO : EPOCH 3 - PROGRESS: at 63.63% examples, 420300 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:12,827 : INFO : EPOCH 3 - PROGRESS: at 67.42% examples, 420587 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:13,834 : INFO : EPOCH 3 - PROGRESS: at 71.14% examples, 420857 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:08:14,856 : INFO : EPOCH 3 - PROGRESS: at 74.81% examples, 420254 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:08:15,869 : INFO : EPOCH 3 - PROGRESS: at 78.59% examples, 420575 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:16,872 : INFO : EPOCH 3 - PROGRESS: at 82.38% examples, 421051 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:17,898 : INFO : EPOCH 3 - PROGRESS: at 86.22% examples, 421379 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:18,908 : INFO : EPOCH 3 - PROGRESS: at 89.89% examples, 421086 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:19,909 : INFO : EPOCH 3 - PROGRESS: at 93.49% examples, 420788 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:08:20,915 : INFO : EPOCH 3 - PROGRESS: at 97.28% examples, 421126 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:21,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-29 13:08:21,603 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-29 13:08:21,606 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-29 13:08:21,608 : INFO : EPOCH - 3 : training on 16900026 raw words (11429765 effective words) took 27.1s, 421684 effective words/s\n",
            "2020-10-29 13:08:22,615 : INFO : EPOCH 4 - PROGRESS: at 3.67% examples, 417253 words/s, in_qsize 5, out_qsize 1\n",
            "2020-10-29 13:08:23,630 : INFO : EPOCH 4 - PROGRESS: at 7.39% examples, 419610 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:08:24,637 : INFO : EPOCH 4 - PROGRESS: at 11.24% examples, 424834 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 13:08:25,645 : INFO : EPOCH 4 - PROGRESS: at 14.90% examples, 422773 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 13:08:26,646 : INFO : EPOCH 4 - PROGRESS: at 18.69% examples, 424849 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:27,670 : INFO : EPOCH 4 - PROGRESS: at 22.47% examples, 424571 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:28,689 : INFO : EPOCH 4 - PROGRESS: at 26.20% examples, 424199 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:08:29,710 : INFO : EPOCH 4 - PROGRESS: at 29.98% examples, 423354 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 13:08:30,735 : INFO : EPOCH 4 - PROGRESS: at 33.83% examples, 423981 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:31,748 : INFO : EPOCH 4 - PROGRESS: at 37.61% examples, 424297 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:32,758 : INFO : EPOCH 4 - PROGRESS: at 41.34% examples, 424091 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:33,789 : INFO : EPOCH 4 - PROGRESS: at 45.12% examples, 423682 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:34,802 : INFO : EPOCH 4 - PROGRESS: at 48.91% examples, 423937 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:35,835 : INFO : EPOCH 4 - PROGRESS: at 52.69% examples, 423669 words/s, in_qsize 5, out_qsize 2\n",
            "2020-10-29 13:08:36,840 : INFO : EPOCH 4 - PROGRESS: at 56.48% examples, 424109 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:37,861 : INFO : EPOCH 4 - PROGRESS: at 60.26% examples, 424153 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:38,862 : INFO : EPOCH 4 - PROGRESS: at 63.99% examples, 424261 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:39,867 : INFO : EPOCH 4 - PROGRESS: at 67.71% examples, 424232 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 13:08:40,899 : INFO : EPOCH 4 - PROGRESS: at 71.38% examples, 423464 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 13:08:41,921 : INFO : EPOCH 4 - PROGRESS: at 75.22% examples, 423708 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:08:42,953 : INFO : EPOCH 4 - PROGRESS: at 79.07% examples, 423779 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:08:43,971 : INFO : EPOCH 4 - PROGRESS: at 82.91% examples, 424163 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:44,978 : INFO : EPOCH 4 - PROGRESS: at 86.64% examples, 424108 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:45,993 : INFO : EPOCH 4 - PROGRESS: at 90.36% examples, 423942 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:08:46,994 : INFO : EPOCH 4 - PROGRESS: at 94.03% examples, 423766 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:08:48,008 : INFO : EPOCH 4 - PROGRESS: at 97.87% examples, 424137 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:48,537 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-29 13:08:48,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-29 13:08:48,576 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-29 13:08:48,577 : INFO : EPOCH - 4 : training on 16900026 raw words (11434431 effective words) took 27.0s, 424036 effective words/s\n",
            "2020-10-29 13:08:49,584 : INFO : EPOCH 5 - PROGRESS: at 3.55% examples, 405651 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:50,586 : INFO : EPOCH 5 - PROGRESS: at 7.27% examples, 416228 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:51,599 : INFO : EPOCH 5 - PROGRESS: at 11.00% examples, 417106 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:52,612 : INFO : EPOCH 5 - PROGRESS: at 14.73% examples, 418068 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:08:53,648 : INFO : EPOCH 5 - PROGRESS: at 18.63% examples, 420668 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 13:08:54,667 : INFO : EPOCH 5 - PROGRESS: at 22.35% examples, 420559 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:08:55,679 : INFO : EPOCH 5 - PROGRESS: at 26.14% examples, 421249 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:56,709 : INFO : EPOCH 5 - PROGRESS: at 29.98% examples, 421768 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:57,728 : INFO : EPOCH 5 - PROGRESS: at 33.77% examples, 422141 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:08:58,731 : INFO : EPOCH 5 - PROGRESS: at 37.43% examples, 421743 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 13:08:59,732 : INFO : EPOCH 5 - PROGRESS: at 41.16% examples, 422104 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:09:00,742 : INFO : EPOCH 5 - PROGRESS: at 44.83% examples, 421449 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:09:01,772 : INFO : EPOCH 5 - PROGRESS: at 48.55% examples, 420794 words/s, in_qsize 6, out_qsize 2\n",
            "2020-10-29 13:09:02,775 : INFO : EPOCH 5 - PROGRESS: at 52.28% examples, 421156 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:09:03,785 : INFO : EPOCH 5 - PROGRESS: at 55.94% examples, 420815 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:09:04,800 : INFO : EPOCH 5 - PROGRESS: at 59.73% examples, 421185 words/s, in_qsize 4, out_qsize 1\n",
            "2020-10-29 13:09:05,810 : INFO : EPOCH 5 - PROGRESS: at 63.51% examples, 421666 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:09:06,824 : INFO : EPOCH 5 - PROGRESS: at 67.30% examples, 421955 words/s, in_qsize 6, out_qsize 1\n",
            "2020-10-29 13:09:07,843 : INFO : EPOCH 5 - PROGRESS: at 71.02% examples, 422108 words/s, in_qsize 5, out_qsize 1\n",
            "2020-10-29 13:09:08,838 : INFO : EPOCH 5 - PROGRESS: at 74.81% examples, 422452 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:09:09,845 : INFO : EPOCH 5 - PROGRESS: at 78.42% examples, 421845 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:09:10,859 : INFO : EPOCH 5 - PROGRESS: at 82.14% examples, 421758 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:09:11,861 : INFO : EPOCH 5 - PROGRESS: at 85.93% examples, 422167 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:09:12,864 : INFO : EPOCH 5 - PROGRESS: at 89.71% examples, 422546 words/s, in_qsize 6, out_qsize 0\n",
            "2020-10-29 13:09:13,879 : INFO : EPOCH 5 - PROGRESS: at 93.44% examples, 422511 words/s, in_qsize 5, out_qsize 1\n",
            "2020-10-29 13:09:14,906 : INFO : EPOCH 5 - PROGRESS: at 97.28% examples, 422700 words/s, in_qsize 5, out_qsize 0\n",
            "2020-10-29 13:09:15,573 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-10-29 13:09:15,592 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-10-29 13:09:15,595 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-10-29 13:09:15,597 : INFO : EPOCH - 5 : training on 16900026 raw words (11433006 effective words) took 27.0s, 423242 effective words/s\n",
            "2020-10-29 13:09:15,598 : INFO : training on a 84500130 raw words (57161789 effective words) took 136.6s, 418606 effective words/s\n",
            "2020-10-29 13:09:15,634 : INFO : saving Word2Vec object under model.ja.bin, separately None\n",
            "2020-10-29 13:09:15,635 : INFO : not storing attribute vectors_norm\n",
            "2020-10-29 13:09:15,636 : INFO : not storing attribute cum_table\n",
            "2020-10-29 13:09:16,441 : INFO : saved model.ja.bin\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7pkHfROBj6H",
        "outputId": "57b2fb36-f3d7-440b-9580-172ab575a3cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_ja = Word2Vec.load('model.ja.bin')\n",
        "\n",
        "print(model_ja.wv['犬'])\n",
        "print(model_ja.wv['犬'].shape)\n",
        "model_ja.wv.most_similar(['車'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-29 13:44:32,903 : INFO : loading Word2Vec object from model.ja.bin\n",
            "2020-10-29 13:44:33,744 : INFO : loading wv recursively from model.ja.bin.wv.* with mmap=None\n",
            "2020-10-29 13:44:33,745 : INFO : setting ignored attribute vectors_norm to None\n",
            "2020-10-29 13:44:33,745 : INFO : loading vocabulary recursively from model.ja.bin.vocabulary.* with mmap=None\n",
            "2020-10-29 13:44:33,747 : INFO : loading trainables recursively from model.ja.bin.trainables.* with mmap=None\n",
            "2020-10-29 13:44:33,748 : INFO : setting ignored attribute cum_table to None\n",
            "2020-10-29 13:44:33,749 : INFO : loaded model.ja.bin\n",
            "2020-10-29 13:44:33,931 : INFO : precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-0.83047616  0.7002652   1.8226818  -1.5889463  -1.3526665  -1.01874\n",
            "  1.4335294   1.3037403   0.93054587  2.0960686  -0.81986654  1.5785731\n",
            "  4.042562    0.4744235   1.4421889  -0.04492768 -0.6082116   2.5076668\n",
            "  0.02987989  1.107785    0.23729905  0.08941399 -1.1753266  -1.5561072\n",
            " -0.0824669   1.3361316  -1.0303357   1.5947185   1.255065   -0.5746231\n",
            " -1.1723132   0.7795273   0.0620449   0.81751496 -1.0895228   0.00462517\n",
            "  0.27096602  0.07449397  1.8582736   1.7072538   0.82855135  0.9623953\n",
            "  0.61951864  0.10411737 -0.5599804  -0.12124187 -2.9421556   0.04146991\n",
            " -0.61044574  1.0615283  -0.66029936  0.2995721   0.11796718 -0.6701717\n",
            "  0.01056705 -0.41598317 -1.0229447   1.5194993  -0.41964298 -2.4524255\n",
            " -0.6570432  -0.5400708  -1.1838228   0.16796957  1.2917123  -0.61429083\n",
            " -1.3051951  -0.32676408  0.27216005 -1.0149709  -1.9711257   0.03284217\n",
            " -1.0621338  -0.29972205  0.11460214 -0.3837586  -1.0412369  -0.01990454\n",
            " -0.37102276  1.503586    1.2830892  -1.5605084  -0.24049373  0.5169125\n",
            " -0.83455473  2.4110117   0.27949908  1.8062112   1.1311327  -1.1641494\n",
            "  1.478273    0.40087247  0.48002073  1.2196056   2.4706204   1.0220113\n",
            "  2.5399146   0.06581804  1.5759254   0.26500547]\n",
            "(100,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('車両', 0.8276019096374512),\n",
              " ('客車', 0.7826144695281982),\n",
              " ('貨車', 0.7474372982978821),\n",
              " ('車体', 0.7086012959480286),\n",
              " ('台車', 0.7060954570770264),\n",
              " ('気動車', 0.6966443061828613),\n",
              " ('寝台', 0.6952678561210632),\n",
              " ('電車', 0.6818050742149353),\n",
              " ('モハ', 0.638667106628418),\n",
              " ('全車', 0.638338565826416)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyYK--AdBcrT"
      },
      "source": [
        "### ベクトル空間モデル\n",
        "\n",
        "\n",
        "*   情報検索を行うためのアルゴリズム\n",
        "*   1970年頃から研究が始まる\n",
        " * Salton先生等のSMARTシステムが有名\n",
        "\n",
        "* ベクトル空間上に検索対象データ，検索語をそれぞれベクトルで表現して配置する．\n",
        "* 検索対象データ，検索語の類似度をベクトル計算（コサイン，内積，距離等）により求める。\n",
        "<img src='https://drive.google.com/uc?export=view&id=14u9m4dFPDTmMUa4sMLMErm6CwViEiqpX' width='30%'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzhr6xuYv5u4"
      },
      "source": [
        "### 文書単語行列\n",
        "* 文書(d1～dm)中に出現する単語集合(t1～tn)によって，特徴付けられた行列\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1y4V0uPCEPcm0JH_v0-NHWtz0SW4_bGkc' width='30%'>\n",
        "\n",
        "<br>\n",
        "\n",
        "* 文書単語行列の例:\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1tEOkD8_BnWLuZxf9iiD1zlVCl8Zn7DAv' width='50%'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prbhDcajopBJ"
      },
      "source": [
        "### コサイン計算\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1a226Fn74_d-un3DM-Z_d41yWixYQiYFy' width='60%'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjnKL_6Votxg"
      },
      "source": [
        "分散表現ベクトルのコサイン尺度を計算する関数cosine_sim()を作成し、「car」と「truck」の分散表現ベクトルのコサイン尺度を計算してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ojpNAlmJTq",
        "outputId": "afc00a09-fff8-4838-f9f8-8e625f14ac99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def cosine_sim(w1, w2):\n",
        "  cosine_value = np.dot(model.wv[w1], model.wv[w2]) / (np.linalg.norm(model.wv[w1]) * np.linalg.norm(model.wv[w2]))\n",
        "  \n",
        "  return cosine_value\n",
        "\n",
        "print (cosine_sim('car','truck'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7151368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il7CwmCEpzxf"
      },
      "source": [
        "コサイン尺度は0.7151368と出力され、先ほどの「model.wv.most_similar(['car'])」の結果と同じ値が算出されていることが確認できます。\n",
        "\n",
        "[('driver', 0.7645907402038574), <br>\n",
        " ('cars', 0.7256535291671753), <br>\n",
        " ('motorcycle', 0.7231885194778442), <br>\n",
        " ('taxi', 0.7163602113723755), <br>\n",
        " ('truck', 0.7151368856430054), <br>\n",
        " ('vehicle', 0.6943105459213257), <br>\n",
        "...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMPoB4b-DmNA"
      },
      "source": [
        "#### 確認例題\n",
        "コサイン計算プログラムを利用して、「車」と「電車」の分散表現ベクトルのコサイン尺度を計算してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2y9tXKqBg6U"
      },
      "source": [
        "### 文書分類\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0nx078cBZLr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DnM6Zkwy33I"
      },
      "source": [
        "### 参考文献\n",
        "* https://code.google.com/archive/p/word2vec/"
      ]
    }
  ]
}